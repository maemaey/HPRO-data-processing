{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47264712-d7dd-4e54-8b3c-470f29eb525a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pytorch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpytorch\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbotorch\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgpytorch\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pytorch'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "import pytorch\n",
    "import botorch\n",
    "import gpytorch\n",
    "import fastai\n",
    "from fastai.tabular import *\n",
    "\n",
    "allData = pd.read_csv('combinedData.csv')\n",
    "allData = allData.sort_values(by='Polymer Concentration Real')\n",
    "allData = allData[allData['Fit'] == True]\n",
    "\n",
    "heatData = allData[allData['Heating'] == True]\n",
    "noheatData = allData[allData['Heating'] == False]\n",
    "\n",
    "xHeat = heatData['Polymer Concentration Real']\n",
    "yHeat = heatData['Elastic Modulus']\n",
    "xNoHeat = noheatData['Polymer Concentration Real']\n",
    "yNoHeat = noheatData['Elastic Modulus']\n",
    "\n",
    "plt.scatter(xHeat,yHeat)\n",
    "plt.xlabel('Polymer Concentration')\n",
    "plt.ylabel('Elastic Modulus (bar)')\n",
    "plt.title('Heating Data')\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(xNoHeat,yNoHeat)\n",
    "plt.xlabel('Polymer Concentration')\n",
    "plt.ylabel('Elastic Modulus (bar)')\n",
    "plt.title('No Heating Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb423ad4-f2f5-4c25-987c-0373ac8f5c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: %%python is a cell magic, but the cell body is empty.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25ee0b3-0833-4d51-bd38-18f30a4f1a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_percentiles(xs, ys):\n",
    "\n",
    "    probs = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "\n",
    "    percentiles = [np.percentile(ys, prob, axis=0) for prob in probs]\n",
    "\n",
    "    light=\"#DCBCBC\"\n",
    "    light_highlight=\"#C79999\"\n",
    "    mid=\"#B97C7C\"\n",
    "    mid_highlight=\"#A25050\"\n",
    "    dark=\"#8F2727\"\n",
    "    dark_highlight=\"#7C0000\"\n",
    "    green=\"#00FF00\"\n",
    "\n",
    "    plt.fill_between(xs, percentiles[0], percentiles[8],\n",
    "                  facecolor=light, color=light)\n",
    "    plt.fill_between(xs, percentiles[1], percentiles[7],\n",
    "                  facecolor=light_highlight, color=light_highlight)\n",
    "    plt.fill_between(xs, percentiles[2], percentiles[6],\n",
    "                      facecolor=mid, color=mid)\n",
    "    plt.fill_between(xs, percentiles[3], percentiles[5],\n",
    "                      facecolor=mid_highlight, color=mid_highlight)\n",
    "    plt.plot(xs, percentiles[4], color=dark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888cfe8d-d9d9-4d97-bd8f-01419f8f1be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MyHeteroskedasticGP(X_train, y_train):\n",
    "\n",
    "    model = SingleTaskGP(train_X=X_train, train_Y=y_train)\n",
    "    model.likelihood.noise_covar.register_constraint(\"raw_noise\", GreaterThan(1e-5))\n",
    "\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "\n",
    "    mll.train()\n",
    "    botorch.optim.fit.fit_gpytorch_scipy(mll)\n",
    "\n",
    "    mll.eval()\n",
    "    # test on the training points\n",
    "    # call if X_test just for ease of use\n",
    "    X_test = X_train.clone()\n",
    "\n",
    "    mll.eval()\n",
    "    with torch.no_grad():\n",
    "        posterior = mll.model.posterior(X_test)\n",
    "        test_pred = mll.likelihood(mll.model(X_test))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # watch broadcasting here\n",
    "        observed_var = torch.tensor(\n",
    "                           np.power(mll.model.posterior(X_train).mean.numpy().reshape(-1,) - y_train.numpy(), 2),\n",
    "                           dtype=torch.float\n",
    "        )\n",
    "\n",
    "    # NOW TRAIN HETERO MODEL\n",
    "    model = HeteroskedasticSingleTaskGP(train_X=X_train, train_Y=y_train,\n",
    "                                    train_Yvar=observed_var)\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "\n",
    "    mll.train()\n",
    "    botorch.optim.fit.fit_gpytorch_scipy(mll)\n",
    "\n",
    "    return mll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfe60fc-471a-48b4-b2b9-64057691bf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(xHeat.reshape(-1,1), dtype=torch.float)\n",
    "y_train = torch.tensor(yHeat, dtype=torch.float)\n",
    "\n",
    "mll = MyHeteroskedasticGP(X_train, y_train)\n",
    "\n",
    "X_test=X_train.squeeze(-1)\n",
    "mll.eval()\n",
    "with torch.no_grad():\n",
    "    posterior = mll.model.posterior(X_test)\n",
    "\n",
    "    predictive_noise = torch.exp(mll.model.likelihood.noise_covar.noise_model.posterior(X_test).mean)\n",
    "    # get standard deviation\n",
    "    predictive_noise_std = torch.sqrt(predictive_noise).squeeze(-1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Initialize plot\n",
    "    f, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "\n",
    "    # fit posterior confidence\n",
    "    lower, upper = posterior.mvn.confidence_region()\n",
    "    # get posterior predictive confidence by adding noise from noise model\n",
    "    lower_predictive = lower - 2*predictive_noise_std\n",
    "    upper_predictive = upper + 2*predictive_noise_std\n",
    "\n",
    "    # Plot training data\n",
    "    ax.scatter(X_train.numpy(), y_train.numpy(), c='b', s=1)\n",
    "    # Plot predictive means as blue line\n",
    "    ax.plot(X_test, posterior.mean.numpy(), 'k-')\n",
    "    # Shade between the lower and upper confidence bounds\n",
    "    ax.fill_between(X_test.numpy(),\n",
    "                    lower.numpy(),\n",
    "                    upper.numpy(), alpha=0.5)\n",
    "    ax.fill_between(X_test.numpy(),\n",
    "                    lower_predictive.numpy(),\n",
    "                    upper_predictive.numpy(),\n",
    "                    alpha=0.3)\n",
    "    ax.legend(['Mean', 'Observed Data', 'Posterior Confidence',\n",
    "               'Posterior Predictive Confidence'])\n",
    "plt.title('Heteroskedastic GP')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
